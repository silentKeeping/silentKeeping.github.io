<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>kubernetes on FeixiangFu</title><link>https://fufeixiang.com/t/kubernetes/</link><description>Recent content in kubernetes on FeixiangFu</description><generator>Hugo -- gohugo.io</generator><language>zh-ch</language><copyright>© 2023 FeixiangFu</copyright><lastBuildDate>Fri, 08 Nov 2019 19:53:19 +0800</lastBuildDate><atom:link href="https://fufeixiang.com/t/kubernetes/index.xml" rel="self" type="application/rss+xml"/><item><title>高可用prometheus监控集群搭建(四)</title><link>https://fufeixiang.com/2019/11/k8s-prometheus-4/</link><pubDate>Fri, 08 Nov 2019 19:53:19 +0800</pubDate><guid>https://fufeixiang.com/2019/11/k8s-prometheus-4/</guid><description>Prometheus可以定义警报规则，满足条件时触发警报，并推送到Alertmanager服务。Alertmanager支持高可用的集群部署，负责管理、整合和分发警报到不通目的地，并能做到告警收敛 本例采用statefulset方式部署3个实例的Alertmanager高可用集群
Alertmanager集群部署 # 创建alertmanager数据目录 # $ mkdir /data/alertmanager 创建storageclass # $ cat storageclass.yaml apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: alertmanager-lpv provisioner: kubernetes.io/no-provisioner volumeBindingMode: WaitForFirstConsumer 创建local volume # $ cat pv.</description></item><item><title>高可用prometheus监控集群搭建(三)</title><link>https://fufeixiang.com/2019/11/k8s-prometheus-3/</link><pubDate>Fri, 08 Nov 2019 14:53:19 +0800</pubDate><guid>https://fufeixiang.com/2019/11/k8s-prometheus-3/</guid><description>&lt;blockquote>
&lt;p>Prometheus的联邦模式，支持了集群的分层扩展及跨服务扩展。
&lt;code>分层扩展&lt;/code>允许Prometheus扩展到多数据中心、大规模主机集群，树型拓扑
&lt;code>跨服务扩展&lt;/code>是不同类别的监控指标项由不同的prometheus server分别收集
在多k8s集群模式下，每个集群部署prometheus server用于收集该集群相关指标,借助prometheus联邦模式，实现监控数据的统一收集展现及告警通知&lt;/p>
&lt;/blockquote></description></item><item><title>高可用prometheus监控集群搭建(二)</title><link>https://fufeixiang.com/2019/11/k8s-prometheus-2/</link><pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2019/11/k8s-prometheus-2/</guid><description>&lt;blockquote>
&lt;p>Prometheus使用exporter工具来暴露主机和应用程序上的指标，目前有很多可用于各种目的的exporter(&lt;a href="https://prometheus.io/docs/instrumenting/exporters/" target="_blank">
https://prometheus.io/docs/instrumenting/exporters/&lt;/a>)&lt;/p>
&lt;/blockquote></description></item><item><title>高可用prometheus监控集群搭建(一)</title><link>https://fufeixiang.com/2019/11/k8s-prometheus-1/</link><pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2019/11/k8s-prometheus-1/</guid><description>简介 # Prometheus是一个开源的监控系统，通过抓取或拉取应用程序中暴露的时间序列数据来工作。时间序列数据通常由应用程序本身通过客户端库或者成为exporter的代理来作为HTTP端点暴露。目前已经存在很多exporter和客户端库，支持多种编程语言、框架和开源应用程序。
官方架构图 # Prometheus通过配置target，来抓取对应主机、进程、服务或应用程序的指标。一组具有相同角色的target被称为job。比如，定义kubernetes-nodes的job，来抓取集群所有主机的相关指标 服务发现（target） 静态资源列表 基于文件的发现，可使用自动化配置管理工具自动更新 自动发现，支持基于AWS/Consul/dns/kubernetes/marathon等的服务发现 Prometheus将收集时间序列数据存储在本地，也可以配置remote_write存储到其它时间序列数据库，比如OpenTSDB、InfluxDB、M3DB等 可视化: Prometheus内置了web UI，也可以和功能强大的开源仪表板Grafana集成，可自定义dashboard满足各种定制化需求 聚合和告警: Prometheus可以查询和聚合时间序列数据，并创建规则来记录常用的查询和聚合。还可以定义警报规则，满足条件时触发警报，并推送到Alertmanager服务。Alertmanagr支持高可用的集群部署，负责管理、整合和分发警报到不通目的地，并能做到告警收敛 数据模型 # Prometheus使用一个多维时间序列数据模型，结合了时间序列名称和称为标签(label)的键/值对，这些标签提供了维度。每个时间序列由时间序列名称和标签的组合唯一标识。 &amp;lt;time series name&amp;gt; {&amp;lt;label name&amp;gt;=&amp;lt;label value&amp;gt;,...}
machine_cpu_cores{beta_kubernetes_io_arch=&amp;ldquo;amd64&amp;rdquo;,beta_kubernetes_io_os=&amp;ldquo;linux&amp;rdquo;,instance=&amp;ldquo;192.168.1.51&amp;rdquo;,job=&amp;ldquo;kubernetes-cadvisor&amp;rdquo;,kubernetes_io_arch=&amp;ldquo;amd64&amp;rdquo;,kubernetes_io_hostname=&amp;ldquo;192.168.1.51&amp;rdquo;,kubernetes_io_os=&amp;ldquo;linux&amp;rdquo;} 2 machine_cpu_cores收集的是主机的cpu核数，taget label标识了是job kubernetes-cadvisor抓取的，instance 192.</description></item><item><title>k8s1.14.6集群搭建之kube-flannel部署</title><link>https://fufeixiang.com/2019/08/k8s1.14.6-flannel/</link><pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2019/08/k8s1.14.6-flannel/</guid><description>&lt;h4 class="relative group">1.Daemonset方式
&lt;div id="1daemonset方式" class="anchor">&lt;/div>
&lt;span
class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
style="text-decoration-line: none !important;" href="#1daemonset%e6%96%b9%e5%bc%8f" aria-label="锚点">#&lt;/a>
&lt;/span>
&lt;/h4></description></item><item><title>k8s1.14.6集群搭建之kube-proxy部署</title><link>https://fufeixiang.com/2019/08/k8s1.14.6-kube-proxy/</link><pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2019/08/k8s1.14.6-kube-proxy/</guid><description>kube-proxy组件的部署，可以选择使用Daemonset的方式或者StaticPod的方式
Daemonset方式保证在加入集群的节点上都运行kube-proxy Pod
StaticPod是由kubectl进行管理的运行在该Node上的Pod，不能通过apiserver进行管理
1. Daemonset方式 # 在master节点上创建kube-proxy的CRD
$ cd /root/k8s-1.14.6/manifests $ kubeclt apply -f kube-proxy.yaml $ cat kube-proxy.yaml kind: ConfigMap apiVersion: v1 metadata: labels: app: kube-proxy name: kube-proxy namespace: kube-system data: config.</description></item><item><title>k8s1.14.6集群搭建之node节点部署</title><link>https://fufeixiang.com/2019/08/k8s1.14.6-node/</link><pubDate>Fri, 23 Aug 2019 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2019/08/k8s1.14.6-node/</guid><description>&lt;h4 class="relative group">前言
&lt;div id="前言" class="anchor">&lt;/div>
&lt;span
class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
style="text-decoration-line: none !important;" href="#%e5%89%8d%e8%a8%80" aria-label="锚点">#&lt;/a>
&lt;/span>
&lt;/h4>
&lt;blockquote>
&lt;p>在部署k8s node节点时，kubelet要与apiserver交互，在双方没有互信的情况下，如何通过master的认证鉴权？kubelet bootstrap就解决了这个问题，本文使用Bootstrap Token Authentication的认证方式，使得kubelet通过apiserver的认证、获取apiserver的CA证书，并成功注册到集群中&lt;/p>
&lt;/blockquote></description></item><item><title>k8s1.14.6集群搭建之apiserver部署</title><link>https://fufeixiang.com/2019/08/k8s1.14.6-apiserver/</link><pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2019/08/k8s1.14.6-apiserver/</guid><description>&lt;h4 class="relative group">1. 创建自签名CA及相关证书
&lt;div id="1-创建自签名ca及相关证书" class="anchor">&lt;/div>
&lt;span
class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
style="text-decoration-line: none !important;" href="#1-%e5%88%9b%e5%bb%ba%e8%87%aa%e7%ad%be%e5%90%8dca%e5%8f%8a%e7%9b%b8%e5%85%b3%e8%af%81%e4%b9%a6" aria-label="锚点">#&lt;/a>
&lt;/span>
&lt;/h4>
&lt;p>1.1 创建自签名CA(apiserver访问相关)&lt;/p></description></item><item><title>k8s1.14.6集群搭建之controller-manager部署</title><link>https://fufeixiang.com/2019/08/k8s1.14.6-controller-manager/</link><pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2019/08/k8s1.14.6-controller-manager/</guid><description>&lt;h4 class="relative group">1. 创建kubeconfig
&lt;div id="1-创建kubeconfig" class="anchor">&lt;/div>
&lt;span
class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
style="text-decoration-line: none !important;" href="#1-%e5%88%9b%e5%bb%bakubeconfig" aria-label="锚点">#&lt;/a>
&lt;/span>
&lt;/h4>
&lt;p>创建controller-manager访问apiserver的kubeconfig&lt;/p></description></item><item><title>k8s1.14.6集群搭建之ETCD集群部署</title><link>https://fufeixiang.com/2019/08/k8s1.14.6-etcd/</link><pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2019/08/k8s1.14.6-etcd/</guid><description>&lt;h4 class="relative group">1. 创建自签名CA及相关证书
&lt;div id="1-创建自签名ca及相关证书" class="anchor">&lt;/div>
&lt;span
class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
style="text-decoration-line: none !important;" href="#1-%e5%88%9b%e5%bb%ba%e8%87%aa%e7%ad%be%e5%90%8dca%e5%8f%8a%e7%9b%b8%e5%85%b3%e8%af%81%e4%b9%a6" aria-label="锚点">#&lt;/a>
&lt;/span>
&lt;/h4>
&lt;p>1.1 创建自签名CA&lt;/p></description></item><item><title>k8s1.14.6集群搭建之scheduler部署</title><link>https://fufeixiang.com/2019/08/k8s1.14.6-scheduler/</link><pubDate>Thu, 22 Aug 2019 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2019/08/k8s1.14.6-scheduler/</guid><description>&lt;h4 class="relative group">1. 创建kubeconfig
&lt;div id="1-创建kubeconfig" class="anchor">&lt;/div>
&lt;span
class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
&lt;a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
style="text-decoration-line: none !important;" href="#1-%e5%88%9b%e5%bb%bakubeconfig" aria-label="锚点">#&lt;/a>
&lt;/span>
&lt;/h4>
&lt;p>创建scheduler访问的apiserver的kubeconfig&lt;/p></description></item><item><title>Kubernetes集群部署</title><link>https://fufeixiang.com/2018/08/k8s-deploy/</link><pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate><guid>https://fufeixiang.com/2018/08/k8s-deploy/</guid><description>k8s是一个Google开源的容器集群管理平台，如今风靡一时，了解并掌握这门技术变得尤为重要。本文将介绍如何搭建一套简单的k8s集群并部署pod、kubernetes-dashboard。关于k8s架构及其组件的详细概念请自行搜索查阅。
集群节点规划及架构 # 节点 IP service master 192.168.196.134 etcd,flannel,docker,kubernetes-master,docker-distribution,nginx node1 192.168.196.135 flannel,docker,kubernetes-node node2 192.168.196.136 flannel,docker,kubernetes-node 对于高可用和容错的Kubernetes生产和部署，需要多个主节点和一个单独的etcd集群
服务安装 # etcd # 所有关于集群状态的配置信息都以key/value对的形式存储在etcd中，这些状态显示了集群中包含的节点和需要在其中运行的pods 本例只是etcd单机部署，在master节点上yum安装etcd并修改etcd.conf，启动etcd
$ grep ^[^#] /etc/etcd/etcd.conf ETCD_DATA_DIR=&amp;#34;/var/lib/etcd/default.etcd&amp;#34; ETCD_LISTEN_CLIENT_URLS=&amp;#34;http://192.168.196.134:2379&amp;#34; ETCD_NAME=etcd1 ETCD_INITIAL_ADVERTISE_PEER_URLS=&amp;#34;http://192.</description></item></channel></rss>